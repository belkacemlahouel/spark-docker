# Base image with Java and Python
FROM openjdk:11-slim

RUN apt-get update && \
    apt-get install -y sudo ssh wget curl vim nano && \
    apt-get clean

RUN echo "root:root123" | chpasswd

RUN useradd -m -s /bin/bash hadoop && \
    echo "hadoop:hadoop123" | chpasswd && \
    usermod -aG sudo hadoop

RUN sed -i 's/^#\?PermitRootLogin .*/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    sed -i 's/^#\?PasswordAuthentication .*/PasswordAuthentication yes/' /etc/ssh/sshd_config

USER root
EXPOSE 22

USER hadoop
WORKDIR /home/hadoop

# Setup passwordless SSH for hadoop user
RUN ssh-keygen -t rsa -f ~/.ssh/id_rsa -q -N "" && \
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && \
    chmod 600 ~/.ssh/authorized_keys

ARG HADOOP_VERSION=3.4.2

USER root

RUN wget "https://dlcdn.apache.org/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz" && \
    tar -xvzf "hadoop-${HADOOP_VERSION}.tar.gz"

RUN rm "hadoop-${HADOOP_VERSION}.tar.gz"
RUN mv "hadoop-${HADOOP_VERSION}" /usr/local/hadoop

RUN chown -R hadoop:hadoop /usr/local/hadoop
RUN chmod 700 /home/hadoop/.ssh
RUN chown -R hadoop:hadoop /home/hadoop/.ssh

USER hadoop

RUN echo '\
export JAVA_HOME=/usr/local/openjdk-11\n\
export HADOOP_HOME=/usr/local/hadoop\n\
export HADOOP_INSTALL=$HADOOP_HOME\n\
export HADOOP_MAPRED_HOME=$HADOOP_HOME\n\
export HADOOP_COMMON_HOME=$HADOOP_HOME\n\
export HADOOP_HDFS_HOME=$HADOOP_HOME\n\
export HADOOP_YARN_HOME=$HADOOP_HOME\n\
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native\n\
export PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH\n\
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"\n\
export HDFS_NAMENODE_USER=hadoop\n\
export HDFS_DATANODE_USER=hadoop\n\
export HDFS_SECONDARYNAMENODE_USER=hadoop\n' >> /home/hadoop/.bashrc

ENV JAVA_HOME=/usr/local/openjdk-11
ENV HADOOP_HOME=/usr/local/hadoop
ENV HADOOP_INSTALL=${HADOOP_HOME}
ENV HADOOP_MAPRED_HOME=${HADOOP_HOME}
ENV HADOOP_COMMON_HOME=${HADOOP_HOME}
ENV HADOOP_HDFS_HOME=${HADOOP_HOME}
ENV HADOOP_YARN_HOME=${HADOOP_HOME}
ENV HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/lib/native
ENV PATH=${HADOOP_HOME}/sbin:${HADOOP_HOME}/bin:${JAVA_HOME}/bin:${PATH}
ENV HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"
ENV HDFS_NAMENODE_USER=hadoop
ENV HDFS_DATANODE_USER=hadoop
ENV HDFS_SECONDARYNAMENODE_USER=hadoop

# setup HDFS config files (core-site.xml)
RUN echo \
'<?xml version="1.0"?>\n\
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>\n\
<configuration>\n\
  <property>\n\
    <name>fs.defaultFS</name>\n\
    <value>hdfs://hdfs-namenode:9000</value>\n\
  </property>\n\
</configuration>' > /usr/local/hadoop/etc/hadoop/core-site.xml

# setup HDFS config files (hdfs-site.xml)
RUN mkdir -p /home/hadoop/hdfs/namenode /home/hadoop/hdfs/datanode && \
    chown -R hadoop:hadoop /home/hadoop/hdfs

RUN echo \
'<?xml version="1.0"?>\n\
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>\n\
<configuration>\n\
  <property>\n\
    <name>dfs.replication</name>\n\
    <value>1</value>\n\
  </property>\n\
  <property>\n\
    <name>dfs.name.dir</name>\n\
    <value>file:///home/hadoop/hdfs/namenode</value>\n\
  </property>\n\
  <property>\n\
    <name>dfs.data.dir</name>\n\
    <value>file:///home/hadoop/hdfs/datanode</value>\n\
  </property>\n\
</configuration>' > /usr/local/hadoop/etc/hadoop/hdfs-site.xml

COPY hdfs-starter.sh /hdfs-starter.sh
RUN ls -l /hdfs-starter.sh

USER root

RUN chmod +x /hdfs-starter.sh
ENTRYPOINT ["bash", "/hdfs-starter.sh"]
